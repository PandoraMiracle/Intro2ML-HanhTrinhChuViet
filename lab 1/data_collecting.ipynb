{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c035704",
   "metadata": {},
   "source": [
    "# Data collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b210c5",
   "metadata": {},
   "source": [
    "## a.Functions used for data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc69e91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\hcmus_document\\năm 3\\kì 1\\machine learning\\intro2ml-hanhtrinhchuviet\\lab 1\\.venv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\hcmus_document\\năm 3\\kì 1\\machine learning\\intro2ml-hanhtrinhchuviet\\lab 1\\.venv\\lib\\site-packages (from bs4) (4.14.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\hcmus_document\\năm 3\\kì 1\\machine learning\\intro2ml-hanhtrinhchuviet\\lab 1\\.venv\\lib\\site-packages (from beautifulsoup4->bs4) (4.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\hcmus_document\\năm 3\\kì 1\\machine learning\\intro2ml-hanhtrinhchuviet\\lab 1\\.venv\\lib\\site-packages (from beautifulsoup4->bs4) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'd:\\HCMUS_Document\\Năm 3\\Kì 1\\Machine Learning\\Intro2ML-HanhTrinhChuViet\\lab 1\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ad393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import os, csv, re, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin,urlsplit, urlunsplit, parse_qsl, urlencode\n",
    "\n",
    "s = requests.Session()\n",
    "def get_soup(url, timeout=20):\n",
    "    r = s.get(url, timeout=timeout)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    return BeautifulSoup(r.text, \"html.parser\") \n",
    "\n",
    "def clean_text(t):\n",
    "    return re.sub(r\"\\s+\", \" \", (t or \"\")).strip()\n",
    "\n",
    "def parse_price_ty_vnd(text):\n",
    "    if not text: return None, None\n",
    "    t = clean_text(text).lower()\n",
    "    raw = t\n",
    "    list = t.split(\" \")\n",
    "    total = 0\n",
    "    for i in range(len(list)):\n",
    "        if \"tỷ\" in list[i]:\n",
    "            total = total + int(list[i-1])\n",
    "        elif \"triệu\" in list[i]:\n",
    "            total = total + int(list[i-1])/1000\n",
    "    return total, raw\n",
    "\n",
    "# Sửa parse_area_m2 để hiểu cả 'm 2', 'm^2', 'm²'\n",
    "def parse_area_m2(text):\n",
    "    if not text: return None\n",
    "    t = clean_text(text).lower()\n",
    "    # Chuẩn hoá các biến thể 'm 2', 'm ^ 2', 'm²' -> 'm2'\n",
    "    t = t.replace(\"m²\", \"m2\")\n",
    "    t = re.sub(r\"m\\s*\\^\\s*2\", \"m2\", t)\n",
    "    t = re.sub(r\"m\\s*2\", \"m2\", t)\n",
    "    m = re.search(r\"([\\d\\.,]+)\\s*m2\\b\", t)\n",
    "    if not m: return None\n",
    "    s = m.group(1).replace(\",\", \".\")\n",
    "    s = re.sub(r\"[^0-9.]\", \"\", s)\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def first_int(text):\n",
    "    if not text: return None\n",
    "    m = re.search(r\"\\d+\", text)\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "def extract_info_attr_rows(soup):\n",
    "    \"\"\"\n",
    "    Đọc từng dòng thuộc tính trong div.info-attr.clearfix:\n",
    "      <div class=\"info-attr clearfix\">\n",
    "        <span>Diện tích sử dụng</span>\n",
    "        <span>78 m<sup>2</sup></span>\n",
    "      </div>\n",
    "    Trả về dict {label_lower: value_text}\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    # Tất cả dòng thuộc tính\n",
    "    rows = soup.select(\"div.info-attr.clearfix\")\n",
    "    # Fallback nếu DOM khác một chút\n",
    "    if not rows:\n",
    "        container = soup.select_one(\"div.info-attrs.clearfix\")\n",
    "        if container:\n",
    "            rows = container.select(\"div.info-attr\")\n",
    "\n",
    "    for row in rows:\n",
    "        spans = row.find_all(\"span\", recursive=False)  # ưu tiên span con trực tiếp\n",
    "        if len(spans) >= 2:\n",
    "            label = clean_text(spans[0].get_text(\" \", strip=True)).lower()\n",
    "            # Lấy value không chèn delimiter để 'm' + <sup>2> thành 'm2' (get_text(\"\", strip=True))\n",
    "            value = clean_text(spans[1].get_text(\"\", strip=True))\n",
    "            if label and value:\n",
    "                info[label] = value\n",
    "        else:\n",
    "            # Trường hợp hiếm: label:value chung một span\n",
    "            t = clean_text(row.get_text(\" \", strip=True))\n",
    "            if \":\" in t:\n",
    "                k, v = t.split(\":\", 1)\n",
    "                k = clean_text(k).lower()\n",
    "                v = clean_text(v)\n",
    "                if k and v:\n",
    "                    info[k] = v\n",
    "    return info\n",
    "\n",
    "def pick_value(pairs, keys):\n",
    "    for lab, val in pairs.items():\n",
    "        lab_l = lab.lower()\n",
    "        if any(k in lab_l for k in keys):\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "def parse_detail_htmlparser(url):\n",
    "    soup = get_soup(url)\n",
    "    if not soup: return None\n",
    "\n",
    "    # Tiêu đề\n",
    "    h1 = soup.find(\"h1\")\n",
    "    tieu_de = clean_text(h1.get_text(\" \")) if h1 else None\n",
    "\n",
    "    # Giá raw từ div.price -> quy đổi bằng parse_price_ty_vnd (đơn vị tỷ)\n",
    "    price_el = soup.find(\"div\", class_=\"price\")\n",
    "    gia_text = clean_text(price_el.get_text(\" \")) if price_el else None\n",
    "    gia_vnd, gia_raw = parse_price_ty_vnd(gia_text)\n",
    "\n",
    "    # Địa chỉ\n",
    "    addr_el = soup.find(\"div\", class_=\"address\")\n",
    "    dia_chi = clean_text(addr_el.get_text(\" \")) if addr_el else None\n",
    "\n",
    "    # Giới thiệu\n",
    "    desc_el = soup.find(\"div\", class_=\"info-content-body\")\n",
    "    gioi_thieu = clean_text(desc_el.get_text(\"\\n\")) if desc_el else None\n",
    "\n",
    "    # Thuộc tính trong các dòng info-attr\n",
    "    pairs = extract_info_attr_rows(soup)\n",
    "\n",
    "    # Diện tích sử dụng / đất\n",
    "    dt_sd_text  = pick_value(pairs, [\"diện tích sử dụng\", \"dien tich su dung\", \"dtsd\"])\n",
    "    dt_dat_text = pick_value(pairs, [\"diện tích đất\", \"dien tich dat\", \"dt đất\", \"dt dat\"])\n",
    "    if not dt_dat_text:\n",
    "        # Fallback: nhiều tin chỉ có 'Diện tích'\n",
    "        dt_dat_text = pick_value(pairs, [\"diện tích\", \"dien tich\"])\n",
    "\n",
    "    dien_tich_su_dung_m2 = parse_area_m2(dt_sd_text) if dt_sd_text else None\n",
    "    dien_tich_dat_m2     = parse_area_m2(dt_dat_text) if dt_dat_text else None\n",
    "\n",
    "    # Phòng ngủ / nhà tắm (đã lấy được theo bạn, giữ nguyên cách đọc từ pairs)\n",
    "    phong_ngu_text = pick_value(pairs, [\"phòng ngủ\",\"số phòng ngủ\",\"so phong ngu\",\"pn\"])\n",
    "    nha_tam_text   = pick_value(pairs, [\"phòng tắm\",\"nhà tắm\",\"toilet\",\"wc\",\"số toilet\",\"so toilet\"])\n",
    "    phong_ngu = first_int(phong_ngu_text)\n",
    "    nha_tam   = first_int(nha_tam_text)\n",
    "\n",
    "    return {\n",
    "        \"tieu_de\": tieu_de,\n",
    "        \"link\": url,\n",
    "        \"gia_raw\": gia_raw,\n",
    "        \"gia_vnd\": gia_vnd,\n",
    "        \"dia_chi\": dia_chi,\n",
    "        \"dien_tich_dat_m2\": dien_tich_dat_m2,\n",
    "        \"dien_tich_su_dung_m2\": dien_tich_su_dung_m2,\n",
    "        \"phong_ngu\": phong_ngu,\n",
    "        \"nha_tam\": nha_tam,\n",
    "        \"phap_ly\": pick_value(pairs, [\"pháp lý\",\"phap ly\",\"giấy tờ\",\"giay to\",\"tinh trang phap ly\"]),\n",
    "        \"gioi_thieu\": gioi_thieu\n",
    "    }\n",
    "\n",
    "PATTERN_DETAIL = re.compile(r\"-id(\\d{5,})\", re.I)  # nhận diện và trích ad_id\n",
    "\n",
    "def extract_listing_links(listing_soup, base_url):\n",
    "    links = []\n",
    "    seen = set()\n",
    "    if not listing_soup:\n",
    "        return links\n",
    "    for a in listing_soup.select(\"a[href]\"):\n",
    "        href = a.get(\"href\",\"\")\n",
    "        if not href or href.startswith(\"#\") or \"javascript:\" in href:\n",
    "            continue\n",
    "        full = urljoin(base_url, href).split(\"?\")[0]\n",
    "        m = PATTERN_DETAIL.search(full)\n",
    "        if (\"mogi.vn\" in full) and m and full not in seen:\n",
    "            seen.add(full)\n",
    "            links.append(full)\n",
    "    return links\n",
    "\n",
    "\n",
    "def set_cp_param(url, page: int) -> str:\n",
    "    parts = urlsplit(url)\n",
    "    q = parse_qsl(parts.query, keep_blank_values=True)\n",
    "    out = []\n",
    "    seen_cp = False\n",
    "    for k, v in q:\n",
    "        if k.lower() == \"cp\":\n",
    "            out.append((\"cp\", str(page)))\n",
    "            seen_cp = True\n",
    "        else:\n",
    "            out.append((k, v))\n",
    "    if not seen_cp:\n",
    "        out.append((\"cp\", str(page)))\n",
    "    new_query = urlencode(out, doseq=True)\n",
    "    return urlunsplit((parts.scheme, parts.netloc, parts.path, new_query, parts.fragment))\n",
    "\n",
    "\n",
    "def collect_links_by_cp(base_url, start_page=1, max_pages=30, sleep_range=(1.0, 2.0), break_no_new_pages=2):\n",
    "    all_links = []\n",
    "    seen_ids = set()\n",
    "    no_new = 0\n",
    "\n",
    "    for page in range(start_page, start_page + max_pages):\n",
    "        page_url = set_cp_param(base_url, page)\n",
    "        soup = get_soup(page_url)\n",
    "        if not soup:\n",
    "            print(\"Dừng do không tải được trang:\", page_url)\n",
    "            break\n",
    "\n",
    "        links = extract_listing_links(soup, page_url)\n",
    "\n",
    "        # Lọc link mới theo ad_id\n",
    "        new_links = []\n",
    "        for u in links:\n",
    "            m = PATTERN_DETAIL.search(u)\n",
    "            adid = m.group(1) if m else None\n",
    "            if adid and adid not in seen_ids:\n",
    "                seen_ids.add(adid)\n",
    "                new_links.append(u)\n",
    "\n",
    "        print(f\"Trang cp={page}: {len(new_links)}/{len(links)} link mới; tổng {len(all_links)+len(new_links)}\")\n",
    "\n",
    "        if not new_links:\n",
    "            no_new += 1\n",
    "        else:\n",
    "            no_new = 0\n",
    "\n",
    "        all_links.extend(new_links)\n",
    "\n",
    "        if no_new >= break_no_new_pages:\n",
    "            print(\"Không thấy link mới trong nhiều trang liên tiếp → dừng.\")\n",
    "            break\n",
    "\n",
    "        time.sleep(random.uniform(*sleep_range))\n",
    "\n",
    "    return all_links\n",
    "\n",
    "def ensure_csv(file_path, fieldnames):\n",
    "    new = not os.path.exists(file_path)\n",
    "    f = open(file_path, \"a\", newline=\"\", encoding=\"utf-8-sig\")\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    if new:\n",
    "        w.writeheader()\n",
    "    return f, w\n",
    "\n",
    "def ad_id_from_url(u):\n",
    "    m = PATTERN_DETAIL.search(u)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def crawl_details_to_csv(detail_links, out_csv=\"./Data/mogi_dump.csv\",\n",
    "                         batch_size=100, sleep_range=(1.0, 2.0)):\n",
    "    # các cột sẽ ghi\n",
    "    cols = [\n",
    "        \"ad_id\",\"tieu_de\",\"link\",\"dia_chi\",\"gia_raw\",\"gia_vnd\",\n",
    "        \"dien_tich_dat_m2\",\"dien_tich_su_dung_m2\",\"phong_ngu\",\"nha_tam\",\"phap_ly\",\"gioi_thieu\"\n",
    "    ]\n",
    "    f, w = ensure_csv(out_csv, cols)\n",
    "    written = 0\n",
    "    batch = []\n",
    "\n",
    "    try:\n",
    "        for i, url in enumerate(detail_links, 1):\n",
    "            try:\n",
    "                item = parse_detail_htmlparser(url)  # dùng parser bạn đã xây\n",
    "                if not item:\n",
    "                    continue\n",
    "                item[\"ad_id\"] = ad_id_from_url(url)\n",
    "                # chỉ giữ các cột cần\n",
    "                row = {k: item.get(k) for k in cols}\n",
    "                batch.append(row)\n",
    "            except Exception as e:\n",
    "                print(\"Lỗi parse:\", url, e)\n",
    "\n",
    "            # ghi theo lô\n",
    "            if len(batch) >= batch_size:\n",
    "                w.writerows(batch)\n",
    "                written += len(batch)\n",
    "                print(f\"Đã ghi {written} bản ghi vào {out_csv}\")\n",
    "                batch.clear()\n",
    "\n",
    "            time.sleep(random.uniform(*sleep_range))  # kiểm soát tốc độ\n",
    "\n",
    "        # flush phần còn lại\n",
    "        if batch:\n",
    "            w.writerows(batch)\n",
    "            written += len(batch)\n",
    "            print(f\"Đã ghi {written} bản ghi vào {out_csv}\")\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa54b7",
   "metadata": {},
   "source": [
    "## b.Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "237aec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://mogi.vn/ho-chi-minh/quan-2/mua-nha\"\n",
    "\n",
    "#link_list = collect_links_by_cp(url, start_page=1, max_pages=1, sleep_range=(0.5, 1.5))\n",
    "\n",
    "#crawl_details_to_csv(link_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60608153",
   "metadata": {},
   "source": [
    "## c.Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6c108f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_case(name):\n",
    "    name = re.sub(r\"\\s+\", \" \", (name or \"\")).strip()\n",
    "    return \" \".join(w[:1].upper() + w[1:] for w in name.split())\n",
    "\n",
    "def extract_quan_only(addr):\n",
    "    \"\"\"\n",
    "    Trả về '1' hoặc 'Tan Phu' nếu tìm được; ngược lại trả None.\n",
    "    Chỉ xử lý 'Quận', KHÔNG xử lý Huyện/TP.\n",
    "    \"\"\"\n",
    "    text = addr or \"\"\n",
    "    # Q.1 / Q1\n",
    "    m = re.search(r\"\\bq\\s*\\.?\\s*([0-9]{1,2})\\b\", text, flags=re.I)\n",
    "    if m:\n",
    "        return f\"{int(m.group(1))}\"\n",
    "    # Quận 1\n",
    "    m = re.search(r\"(?:quận)\\s*([0-9]{1,2})\\b\", text, flags=re.I)\n",
    "    if m:\n",
    "        return f\"{int(m.group(1))}\"\n",
    "    # Quận Tân Phú\n",
    "    m = re.search(r\"(?:quận)\\s*([^,;0-9]+)\", text, flags=re.I)\n",
    "    if m:\n",
    "        return norm_case(m.group(1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f94ca585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (8532, 12)\n",
      "Columns: ['ad_id', 'tieu_de', 'link', 'dia_chi', 'gia_raw', 'gia_vnd', 'dien_tich_dat_m2', 'dien_tich_su_dung_m2', 'phong_ngu', 'nha_tam', 'phap_ly', 'gioi_thieu']\n",
      "Số NaN theo cột trước khi drop:\n",
      "dia_chi                    0\n",
      "phong_ngu                610\n",
      "nha_tam                  613\n",
      "dien_tich_dat_m2           0\n",
      "dien_tich_su_dung_m2    4116\n",
      "gia                        0\n",
      "dtype: int64\n",
      "Sau drop (any missing): (4294, 6)\n",
      "Đã lưu: ./Data/data_predict_price_house.csv | shape: (4293, 6)\n",
      "   quan  dien_tich_dat_m2  dien_tich_su_dung_m2  phong_ngu  nha_tam  gia\n",
      " Gò Vấp             147.0                 479.0       17.0     18.0 16.8\n",
      "Tân Phú             180.0                 179.0       13.0     13.0 23.0\n",
      "     10              53.0                  53.0        2.0      2.0  4.3\n",
      "      9             233.0                 233.0       28.0     28.0 26.0\n",
      "     10             102.0                 102.0        2.0      2.0  3.7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Đọc file CSV\n",
    "path = \"./Data/mogi_dump.csv\"  # đổi nếu cần\n",
    "df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Loaded:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# 2) Chọn và đổi tên cột\n",
    "keep = {\n",
    "    \"dia_chi\": \"dia_chi\",\n",
    "    \"phong_ngu\": \"phong_ngu\",\n",
    "    \"nha_tam\": \"nha_tam\",\n",
    "    \"dien_tich_dat_m2\": \"dien_tich_dat_m2\",\n",
    "    \"dien_tich_su_dung_m2\": \"dien_tich_su_dung_m2\",\n",
    "    \"gia_vnd\": \"gia\" \n",
    "}\n",
    "missing = [c for c in keep.keys() if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Thiếu cột trong file:\", missing)\n",
    "\n",
    "out = df[[c for c in keep.keys() if c in df.columns]].rename(columns=keep)\n",
    "\n",
    "# 3) Chuẩn hoá giá trị trống -> NaN\n",
    "out = out.replace(r'(?i)^\\s*(na|n/a|none|null|nan)?\\s*$', np.nan, regex=True)\n",
    "out = out.replace(r'^\\s*$', np.nan, regex=True)  # chuỗi rỗng/space\n",
    "\n",
    "# 4) Ép kiểu số\n",
    "num_cols = [\"gia\", \"dien_tich_dat_m2\", \"dien_tich_su_dung_m2\", \"phong_ngu\", \"nha_tam\"]\n",
    "for c in num_cols:\n",
    "    if c in out.columns:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "print(\"Số NaN theo cột trước khi drop:\")\n",
    "print(out.isna().sum())\n",
    "\n",
    "# 5) Drop dòng nếu BẤT KỲ cột nào bị NaN\n",
    "out_clean = out.dropna(how=\"any\").copy().reset_index(drop=True)\n",
    "print(\"Sau drop (any missing):\", out_clean.shape)\n",
    "\n",
    "out_clean[\"quan\"] = out_clean[\"dia_chi\"].apply(extract_quan_only)\n",
    "\n",
    "# 7) Loại dòng không có 'quan' và bỏ cột 'dia_chi'\n",
    "out_clean = out_clean.dropna(subset=[\"quan\"]).drop(columns=[\"dia_chi\"])\n",
    "\n",
    "# 8) Sắp xếp lại cột và lưu file\n",
    "cols_order = [\"quan\", \"dien_tich_dat_m2\", \"dien_tich_su_dung_m2\", \"phong_ngu\", \"nha_tam\",\"gia\"]\n",
    "out_clean = out_clean.reindex(columns=cols_order)\n",
    "\n",
    "out_path = \"./Data/data_predict_price_house.csv\"\n",
    "out_clean.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Đã lưu:\", out_path, \"| shape:\", out_clean.shape)\n",
    "print(out_clean.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4b378",
   "metadata": {},
   "source": [
    "# d.Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29807ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (4293, 6)\n",
      "   quan  dien_tich_dat_m2  dien_tich_su_dung_m2  phong_ngu  nha_tam  gia\n",
      " Gò Vấp             147.0                 479.0       17.0     18.0 16.8\n",
      "Tân Phú             180.0                 179.0       13.0     13.0 23.0\n",
      "     10              53.0                  53.0        2.0      2.0  4.3\n",
      "      9             233.0                 233.0       28.0     28.0 26.0\n",
      "     10             102.0                 102.0        2.0      2.0  3.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out_path_test = \"./Data/data_predict_price_house.csv\"\n",
    "data_test = pd.read_csv(out_path_test, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Test data shape:\", data_test.shape)\n",
    "print(data_test.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e03069ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quan</th>\n",
       "      <th>dien_tich_dat_m2</th>\n",
       "      <th>dien_tich_su_dung_m2</th>\n",
       "      <th>phong_ngu</th>\n",
       "      <th>nha_tam</th>\n",
       "      <th>gia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gò Vấp</td>\n",
       "      <td>147.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tân Phú</td>\n",
       "      <td>180.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>233.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      quan  dien_tich_dat_m2  dien_tich_su_dung_m2  phong_ngu  nha_tam   gia\n",
       "0   Gò Vấp             147.0                 479.0       17.0     18.0  16.8\n",
       "1  Tân Phú             180.0                 179.0       13.0     13.0  23.0\n",
       "2       10              53.0                  53.0        2.0      2.0   4.3\n",
       "3        9             233.0                 233.0       28.0     28.0  26.0\n",
       "4       10             102.0                 102.0        2.0      2.0   3.7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
